DuckDuckGo_MCP
Below see some troubleshooting suggestions for getting the DuckDuckGo MCP working.  Let's back up and troubleshoot this.  We will use the record of our troubleshooting to help inform the validation harness process to better handle misbehaving servers.  Also, I will provide a number of API keys here to be saved for use in authentication of MCPs or other tools as needed.

NOTE: PR-8 is not yet complete.  It is not complete untill we have a full PASS for all of the test MCP servers, each tool has been tested, and a validation report created.  Then we have to standardize this process into a replicable and reliable workflow, and test again on the "test mcps"

API Keys:

Octagon DeepSearch
sk_live_PbNOl3Ff8Kx1PWWzhTHcUUjdnmNvZG-yDKuAXnHe1-Fn_Uw9wFjDNebEijj0plrETt-ksGHEitUhsQN4UXQ_Gw

Rijksmuseum API
n6QGCZoq

NCBI/NIH/PubMed API
2a0da4bed69ec5f8536cdea35b756271f509

Brave_Search
BSAoZko4YP0Iv_SY4LooTZMPrJk9vmn

LangSmith Key
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

GitHub Classic Access Token
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

GitHub classic token: mcp_token
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

ideogram_API
xSfrX186WfEIw8N4lT5o3faxxm8aqxmgfeYJeXWfr0u7H_LG-sHNEC0_5jYvFJgenHHGq07k_B5_ZmUJDL7IYg

Chutes fingerprint
d3bgwyXC4hpQNvZVGBq0zoWExDu2Sska


LLM API keys, may need to be configured with the URL endpoints to work:

openai_vscode:
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

GeminiStudioAPI:
AIzaSyC3eRhKZlrio2FfCjNdXOrEBKQ3EYMqGrY

GoogleAPI_all
AIzaSyAtnjwATanRbHLlT8AMp19kk_5s5NvS01w

OpenRouterAPI
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

OpenRouter_Code
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

OpenRouter_test
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

GROK_vscode
xai-LyLp6YhsAL1Q1PSbTCGNiehsMivO2HQJ1gRf7REea2Kj6xk40F3ek62Ka0vgjQ2wuYN8dFGl57NdjKon

GROK_personal
xai-NK92c0sWaYc7wuTjCLlVX8AS3YAlcuoWozOf8ArPfdj6SD7fhSboqiT3zaZrL9XoJmpkotEwMI9laHvT

Thermo Dev 1 (accesses multiple models through Azure Gateway)
2f777dd2f6be409299021d7d789c96a7

Thermo Dev 2 (accesses multiple models through Azure Gateway)
bea5c53878454ad8a3c5ae21d2945c78

GoogleVisionAPI:
AIzaSyBzKLQ3AWrwgfUI6GZQxJZvdidxbXkIx3E

image-upscaling.net client ID:
6e94547852639dccff0102a5bfa7c699

Stability_API
sk-rUDaeO3D6j6kbbhgwZMxhRtKOzHvNzpJnyKWzgXERY0nQgsh

fal.ai
d7e03ce7-ebe2-49ac-a14a-001c0779751e:45ca48f3f2b6422a773304fdf3225e56

Web Searching
Google Search Engines
ThermoSeek
ID: d68a4e7323d2b4c12
Programmatic API key: AIzaSyAtnjwATanRbHLlT8AMp19kk_5s5NvS01w
See: https://developers.google.com/custom-search/v1/introduction
URL: https://cse.google.com/cse?cx=d68a4e7323d2b4c12
<script async src="https://cse.google.com/cse.js?cx=d68a4e7323d2b4c12">
</script>
<div class="gcse-search"></div>

Hive (Reverse image)
0AAMMvXlMpxgt2dwQIiMKhpolzQxnKio

SerpAPI (Reverse image)
d25d97279aeed97f73fbd6f856dea9dafca2e4323de32e83300d2f88c063c27b

Serper
dd4ef88b2323ef75bc77e03bb758984bf028a692

ClarifiAI
4089631501294650977faf81c906f58a

ScraperAPI
28addcfc2b8c43446c34276d467439dc

Brave_Search
BSAoZko4YP0Iv_SY4LooTZMPrJk9vmn

Perplexity
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

Firecrawl
fc-d3e81fb4ba5c4d299f2684f35c6bf986

Alpha Vantage (stocks, etc)
X679LK166YB4XYLW

AIfred git PAT
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

GitKraken
eJwtzLFuwjAQgOF3udkDJBAcb1WXLkUdkNJO1tk5Ezcmts4OhCLevRLK+kvf/wC0lnI+xZEmUCBrpMbuqxblzlXW9m2NzaaSWLlDTdIYK7GRBwcCEser74lX+lhPuqyr8xD1Z3qXbTp23ez+yscOf07f+7cvOg5mu3RLHcrvZgABL6LLPREoMIRMDAKyja+A/cVPKs0meKtHugsm7FXks2BKUcyZWNEFfRC3yKML8QYCaEmeKWssoKY5hOfzH96WUPI=

CannonCoPilot_PAT1
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

JarvisOpenAI_key
sk-proj-Jenw20FKOCrYg4misjZL9Er8RF67LcDBG3_mbLrs-sj3K5TdeOVbK46V9WnBWqnO8XYpBIjQ9LT3BlbkFJPznofNgQz4_h_7LpicYoUrfdNTi6JWVyycfP1Z3UrZHwDv8CvBlQDwcmda21ejFk-i9vJnuyYA

AlphaVantage API Key
FPLKLS4XOXLSMIZM

Context7 Key
ctx7sk-33ff4efb-ef82-41e2-b4fb-b2628f1298f7


Troubleshooting:
Using a DuckDuckGo MCP server involves installing and running the server application and then configuring your AI client (like Cursor or Claude Desktop) to communicate with it via the Model Context Protocol (MCP). The server provides tools for the AI to perform web searches and fetch webpage content. 
Prerequisites
You need the following before you start:
Python 3.10 or newer installed on your system.
An MCP-compatible AI client such as Cursor, Claude Desktop, or a custom agent built with a framework like LangChain.
Basic knowledge of your operating system's command line interface (CLI). 
Step-by-Step Usage
1. Install the Server
You can install the server using pip, Python's package manager: 
bash
pip install duckduckgo-mcp-server
2. Run the Server
Start the server from your terminal. By default, it runs on port 8000: 
bash
python3 -m duckduckgo_mcp_server
You can specify a different port using the --port flag (e.g., python3 -m duckduckgo_mcp_server --port 8080). 
3. Configure Your AI Client 
You need to edit your AI client's configuration file to tell it how to connect to the running server. This process varies by client (see Cursor documentation or Claude Desktop documentation for specifics). 
A typical configuration entry in a JSON config file looks like this: 
json
{
  "mcpServers": {
    "duckduckgo-search": {
      "command": "python3 -m duckduckgo_mcp_server",
      "args": ["--port", "{port}"]
    }
  }
}
After saving the configuration, restart your AI client for the changes to take effect. 
4. Use the Tools in Your AI Client 
Once configured, your AI agent can now use the following tools through natural language prompts: 
search / duckduckgo_search: Queries the web using DuckDuckGo. You can specify a query (required), the number of results (numResults or max_results, default 10), and a safeSearch level (strict, moderate, or off).
Example Prompt: "Use the search tool to find the latest news on the Model Context Protocol."
fetch / get_page_content: Retrieves and cleans text content from a specific URL provided in the search results, making it readable for the language model.
Example Prompt: "Fetch the content from this URL: [link]" 
The server returns structured data, typically in Markdown, which the AI model can easily parse and reason with.

To use the DuckDuckGo Model Context Protocol (MCP) server, you must install the server locally and then configure your AI client (such as Claude Desktop or Cursor) to communicate with it. 
The server provides tools for web search (returning formatted Markdown results) and content fetching (extracting readable text from URLs). 
1. Installation
Depending on your environment, you can install the server using Python or a direct installer: 
Automatic (Claude Desktop): Run npx -y @smithery/cli install @nickclyde/duckduckgo-mcp-server --client claude to automate the setup.
Manual (Python/uv):
Ensure you have Python 3.10+ installed.
Install the package via pip: pip install duckduckgo-mcp-server.
Alternatively, use uv for a fast installation: uv pip install duckduckgo-mcp-server. 
2. Client Configuration
You must add the server to your AI client's configuration file to enable its tools. 
Claude Desktop:
Open the configuration file:
macOS: ~/Library/Application Support/Claude/claude_desktop_config.json
Windows: %APPDATA%\Claude\claude_desktop_config.json
Add the following entry to the mcpServers object:
json
{
  "mcpServers": {
    "ddg-search": {
      "command": "uvx",
      "args": ["duckduckgo-mcp-server"]
    }
  }
}
```

Use code with caution.

Cursor:
Go to Settings > MCP.
Click "Add new MCP Server".
Set the name to duckduckgo-search, the type to command, and enter mcp-duckduckgo (or your specific install command). 
3. Usage & Parameters
Once connected, the AI agent can automatically use these tools during your chat: 
search tool: Accepts a query (string, required) and optional max_results (default 10) or safeSearch (strict/moderate/off).
fetch_content tool: Accepts a url (string, required) to retrieve and clean text from a specific webpage for the LLM to read. 
Note: No API keys are required for DuckDuckGo MCP servers, as they use public search scraping.


To troubleshoot the persistent rate limiting and missing fetch_content tool in your DuckDuckGo (DDG) MCP setup, direct your AI agent to investigate the following options sequentially:
1. Investigate the "Anomaly" Error (Rate Limiting)
The "DDG detected an anomaly" error often indicates that the server's scraping requests are being flagged as bot traffic, regardless of your 30/min limit. 
Check ss_mkt Parameter: Have the agent check the configuration for any region-specific parameters (like ss_mkt=FR). Removing these can sometimes bypass anomaly detection.
Implement a Tool-Level Delay: Since the MCP's internal rate limiting might be too aggressive for DDG's current anti-bot stance, instruct the agent to use a sleep command between search attempts (e.g., 5–10 seconds) rather than relying on the MCP's default timing.
Verify IP/Proxy Status: If the agent has access to the host environment, check if a VPN or proxy is active. DDG's bot detection is more aggressive on known data center or VPN IP ranges. 
2. Locate the Missing fetch_content Tool
If mcp__duckduckgo__duckduckgo_web_search exists but fetch_content does not, it usually stems from a version or configuration mismatch.
Check the MCP Server Version: The fetch_content tool was added to many community DDG servers in late 2025. Have the agent run uv pip install --upgrade duckduckgo-mcp-server to ensure it is using the latest version that includes this tool.
Verify Tool Prefixes: Your logs show the tool as mcp__duckduckgo__duckduckgo_web_search. Some MCP hosts (like Docker or specific Claude Code versions) may incorrectly map or hide certain tools if their names are too long or contain restricted characters.
Inspect mcp list-tools Output: Use the command /mcp list-tools within Claude Code to see the raw JSON definition of the server. This will reveal if fetch_content is present but named differently (e.g., mcp__duckduckgo__get_web_content). 
3. Alternative Search Options
If the DDG server remains unreliable due to scraping blocks, consider these alternatives:
Exa MCP Server: A highly reliable alternative that uses an API key rather than scraping, which completely avoids "anomaly" detection.
Brave Search MCP: Another robust option that requires an API key but provides dedicated developer endpoints to avoid scraping issues.
Sequential Search: Instruct the agent to reduce the max_results (count) in the search query to 1 or 2 to reduce the payload size and the likelihood of triggering a bot check. 
Summary of Actions for the AI Agent
Update: Run uv pip install --upgrade duckduckgo-mcp-server.
Verify: Run /mcp list-tools to find the exact name of the fetch tool.
Wait: Add a 10-second sleep between all search calls to reset DDG's anti-bot cooldown.



Copilot said: Below are multiple investigation paths your Claude
Below are multiple investigation paths your Claude Code agent (and you) can take. I’m going to structure them as hypotheses → quick checks → what to change, so the agent can systematically isolate the failure mode.

From your transcript: the MCP is Connected, the tool exists (mcp__duckduckgo__duckduckgo_web_search), but every call returns:

DDG detected an anomaly in the request, you are likely making requests too quickly.

That message is typically DuckDuckGo bot-detection, not a pure “too many QPS” limit.

Option 1: Confirm this is true DDG bot detection (not an MCP bug)
Hypothesis
The MCP is functioning, but DDG is rejecting the requests based on IP/headers/traffic reputation.

Quick checks
Run the same query from outside Claude Code on the same machine/network.
If you can reproduce DDG blocking in a normal browser or curl-like workflow (even indirectly), it’s network/IP reputation.
Try a single request after a longer quiet period:
sleep 30–120 seconds (not 3–5s), then make one query.
Try changing the query to something extremely common and short:
"weather" / "github" / "news"
What to change / next steps
If the same IP is blocked consistently, you’ll need a different search provider for reliable automation (see Option 6), or route DDG requests through a more “human-like” fetch path (proxy/browser), or reduce automation use of DDG to near-zero.
Option 2: Ensure the agent isn’t accidentally sending bursts (retries, hooks, parallelism)
Hypothesis
The agent (or your hooks) may be triggering multiple calls quickly (e.g., automatic retry logic, validation harness calling several times, parallel agents).

Quick checks
Look in your audit log (AIfred/Jarvis hooks log tool executions) and verify:
How many duckduckgo_web_search calls were actually made.
Whether there are hidden retries.
Ensure you aren’t running multiple Claude sessions concurrently sharing the same IP.
What to change
Add a “DDG throttle” wrapper pattern:
Global: 1 request per 30–60 seconds
Backoff on anomaly: exponential (60s → 120s → 240s) and stop after N failures.
In your validation harness for MCPs: treat DDG as “best-effort” unless backed by an API-based provider.
Option 3: Verify you’re using the right server/tool and its current behavior
Hypothesis
The MCP server you’re running exposes only duckduckgo_web_search (no fetch tool), and its implementation may be using a DDG endpoint that now triggers bot detection.

Quick checks
Inspect the MCP server README/source for the exact tools it exposes.
You referenced fetch_content, but you’re not seeing it—this suggests either:
docs changed,
different version,
or fetch isn’t a separate tool.
Confirm you are running nickclyde/duckduckgo-mcp-server (your notes list that repo).
If you’re running a fork/older version, tool list may differ.
What to change
If the server supports configuration flags (user-agent, safe-search, region, etc.), set them.
If it does not: consider updating to latest version or switching servers/providers.
Option 4: Diagnose environment/network factors (most common cause of DDG anomalies)
Hypothesis
DDG is blocking because of your network egress environment: VPN, corporate network, cloud IP, CGNAT, datacenter IP range, etc.

Quick checks
Are you on:
VPN?
iCloud Private Relay?
corporate network?
a hosted VPS?
Try the same request from:
a phone hotspot (different IP),
disabling VPN,
a different Wi‑Fi network.
What to change
If switching IP fixes it, DDG is effectively unusable from the original network for automation.
Permanent fixes:
Use a paid API search provider (Brave / Perplexity) for reliability.
Or route requests through a browser automation MCP (Playwright/Puppeteer) which can sometimes behave more like a user (still not guaranteed).
Option 5: Reduce DDG usage to “human-in-the-loop” only; validate MCP health differently
Hypothesis
DDG is too unreliable for automated tests; treating it like a deterministic MCP validation target will fail.

Quick checks
Does the server respond with any results ever? If not, it’s not a good automated dependency.
What to change
Redefine validation for DDG MCP as:
“Server connects and tool exists” (structural validation)
plus optional “manual approval run” for functional validation
In Jarvis patterns:
do not use DDG as a hard dependency for automation flows
use it as a fallback when API search is unavailable
Option 6 (Recommended): Add a reliable search provider as primary; keep DDG as fallback
Given your notes: you already planned BraveSearch and Perplexity and you have keys.

Primary alternatives
Brave Search MCP: https://github.com/brave/brave-search-mcp-server (API-keyed, much more automation-friendly)
Perplexity MCP: https://github.com/perplexityai/modelcontextprotocol (API-keyed)
Wikipedia / arXiv MCP for grounding where applicable.
How to operationalize (agent behavior)
Define a selection rule:

If task requires web search:
use BraveSearch MCP (primary)
fallback to Perplexity MCP
fallback to DDG MCP (best-effort, throttled, no retries)
fallback to Playwright-driven browsing (slow but often works)
This also satisfies your roadmap requirement: overlap analysis + selection rules + validation.

The “missing fetch tool” question
It’s very plausible that this DuckDuckGo MCP server only exposes search, not fetch. Many MCPs keep scope narrow (search only), expecting you to use Fetch MCP or browser automation for page retrieval.

Action for the agent:

Stop looking for mcp__duckduckgo__fetch_content unless it’s documented in the specific server version you installed.
Use:
mcp__fetch__... (if you have Fetch MCP enabled), or
mcp__playwright__... to retrieve page content.
Minimal instructions you can give your Claude Code agent right now
Audit how many DDG calls were made (ensure no retries/parallelism).
Wait 120 seconds, then make exactly one DDG call; record result.
Try from a different IP (disable VPN / hotspot) and repeat one call.
If still failing: treat DDG as unreliable, switch primary search to Brave/Perplexity, and update Jarvis selection rules + validation accordingly.
For fetching content: stop expecting a DDG “fetch” tool; use Fetch MCP or Playwright.
Two questions for you (so I can tailor the next steps precisely)
Which DuckDuckGo MCP server implementation are you running (confirm repo/commit or paste your MCP config entry for it)? {Answer: I don't know!!!}
Are you on VPN / a hosted server / corporate network when you run Claude Code? {Answer: No, just a basic home network connection.}





Several open-source DuckDuckGo Model Context Protocol (MCP) servers are available, primarily built in Python or TypeScript. These servers generally do not require API keys as they utilize DuckDuckGo's public search or scraping interfaces. 
Top Community-Maintained Servers
nickclyde/duckduckgo-mcp-server (Python): This is a popular community implementation. It provides web search and specific tools for content fetching and text cleaning.
URL: https://github.com/nickclyde/duckduckgo-mcp-server
zhsama/duckduckgo-mcp-server (Python & TypeScript): Offers a comprehensive Python implementation that supports multiple transport modes including STDIO, HTTP, and SSE.
URL: https://github.com/zhsama/duckduckgo-mcp-server
mmkal/duck-duck-scrape-mcp (TypeScript): A lightweight server that scrapes DuckDuckGo results.
URL: https://github.com/mmkal/duck-duck-scrape-mcp 
Alternative Open Source Implementations
misanthropic-ai/ddg-mcp: A Python-based server specifically designed for LLM integration with automated publishing workflows.
URL: https://github.com/misanthropic-ai/ddg-mcp
kouui/web-search-duckduckgo: Focuses on both searching and summarizing found URL content.
URL: https://github.com/kouui/web-search-duckduckgo
Sunwood-ai-labs/duckduckgo-web-search: A TypeScript implementation designed to demonstrate core MCP concepts like resources and tools.
URL: https://github.com/Sunwood-ai-labs/duckduckgo-web-search
Muhammad-Sarfaraz/duckduckgo-mcp-server: Another TypeScript-based version with built-in support for the MCP Inspector.
URL: https://github.com/Muhammad-Sarfaraz/duckduckgo-mcp-server 
Multi-Search Aggregators
OneSearch MCP (yokingma/one-search-mcp): Integrates DuckDuckGo alongside other engines like Bing and Tavily, including scraping capabilities.
URL: https://github.com/yokingma/one-search-mcp 